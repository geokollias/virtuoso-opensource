   Running SBP 256M scale benchmark from pre-loaded database

In order to avoid loading and data generation which are time consuming we provide a way to use ready SPB database.
Some of commands bellow require access to Amazon S3 storage, for this purpose the 'aws' client must be configured. 

1) Initialize SSD volumes /1s1 and /1s2
$ sudo ./mkvol.sh 

2) Download the SPB 256M database backup from the Amzson S3 bucket

$ cd /1s1/
$ aws s3 cp s3://opl-spb256dataset/spb256db.tar .

3) Decompress the SPB 256M database files, after last command return must have /1s?/dbs/spb256.db files.

$ cd /
$ tar xf /1s1/spb256db.tar 
$ gunzip /1s1/dbs/spb256.db.gz &
$ gunzip /1s2/dbs/spb256.db.gz &
$ wait

4) Next we remove the backup file to do not take space

$ rm /1s1/spb256db.tar 

5) Do a copy of the SPB driver on SSD as logs and other files may take a space

$ cd /home/spb256/
$ cp -R /home/ec2-user/ldbc_spb_bm_2.0/dist /1s2/spb256

6) Do a copy of the the config files for SPB banchmark driver

$ cp *.properties /1s2/spb256

7) Download the SPB 256M scale datasets and query parameters

$ cd /1s2/spb256/
$ aws s3 cp s3://opl-spb256dataset/spb256data.tar .

8) Decompress the SPB 256M dataset and query parameters, after that operation the directory /1s2/spb256/generated must be filled with *.nq.gz and query*.txt files.

$ tar xf spb256data.tar

9) Start the Virtuoso server

$ cd /home/spb256
$ ./virtuoso-t +wait

10) Check the SPB 256M database contains relevant number of triples, the command bellow should return about 256M triples count

$ isql 1111
SQL> sparql select count(*) { ?s ?p ?o };
SQL> exit;

11) Run the SPB driver

$ sh run.sh 

12) Check results from /1s2/spb256/logs

13) Stop the server, and cleanup the transaction log if need to make second run

$ isql 1111 dba dba exec="raw_exit()"
$ rm /1s?/dbs/spb256.trx
